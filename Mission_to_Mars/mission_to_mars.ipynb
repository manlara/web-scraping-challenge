{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the NASA Mars News to be scrapped\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve page with requests module\n",
    "html = browser.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the results, then determine element that contains sought info\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the latest News Title and Paragraph Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all the headlines\n",
    "headline_lists= soup.find('ul', class_=\"item_list\")\n",
    "\n",
    "# Collect top headline and title from list of headlines \n",
    "latest_headline_title = headline_lists.find('div', class_=\"content_title\").text\n",
    "latest_headline_para = headline_lists.find('div', class_=\"article_teaser_body\").text\n",
    "\n",
    "print(f'Latest Headline Title : {latest_headline_title}')\n",
    "print('****************************************************************************************************')\n",
    "print(f'Latest Headline Paragraph: {latest_headline_para}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JPL Mars Space Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the NASA Space Image to be scrapped\n",
    "url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "browser.visit(url)\n",
    "time.sleep(10)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract tag containing url to latest url to current featured mars image\n",
    "article = soup.find('article', class_=\"carousel_item\")\n",
    "\n",
    "# Extract url from the article tag\n",
    "start = article['style'].find(\"/\")\n",
    "end = article['style'].find(\"\\')\")\n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + article['style'][start:end]\n",
    "\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Weather - Scrape the latest Mars weather tweet from the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of Mars weather to be scrapped\n",
    "weather_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "browser.visit(weather_url)\n",
    "time.sleep(10)\n",
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find('div', class_=\"css-901oao r-hkyrab r-1qd0xha r-a023e6 r-16dba41 r-ad9z0x r-bcqeeo r-bnwqim r-qvutc0\")\n",
    "mars_weather = result.find('span', class_=\"css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0\").text.strip()\n",
    "mars_weather\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_facts_url = \"https://space-facts.com/mars/\"\n",
    "tables = pd.read_html(mars_facts_url)\n",
    "mars_facts_df = tables[1]\n",
    "\n",
    "mars_facts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to a HTML table string\n",
    "html_table = mars_facts_df.to_html()\n",
    "html_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Cerberus Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/cerberus_enhanced.tif'}\n",
      "{'title': 'Schiaparelli Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/schiaparelli_enhanced.tif'}\n",
      "{'title': 'Syrtis Major Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/syrtis_major_enhanced.tif'}\n",
      "{'title': 'Valles Marineris Hemisphere', 'img_url': 'http://astropedia.astrogeology.usgs.gov/download/Mars/Viking/valles_marineris_enhanced.tif'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize browser for navigating dom tree\n",
    "def initializeBrowser(url):\n",
    "    browser.visit(url)\n",
    "    time.sleep(5)\n",
    "    html = browser.html\n",
    "    soup = bs(html,'html.parser')\n",
    "    soup.prettify()\n",
    "    \n",
    "    return soup\n",
    "\n",
    "# Returns dictionary containing hemisphere title and image url\n",
    "def getMarsHemisphereUrls(soup):\n",
    "    item_list = soup.find_all('div', class_='item')\n",
    "\n",
    "    hemisphere_image_url = []\n",
    "    base_url = \"https://astrogeology.usgs.gov\"\n",
    "    \n",
    "    for item in item_list:\n",
    "        anchor_tag = item.find('a', class_='itemLink product-item')\n",
    "        \n",
    "        image_title = item.find('h3').text.strip().split(' Enhanced')[0]\n",
    "        url = base_url + anchor_tag['href']\n",
    "        \n",
    "        # Navigate to new url to fetch url of high res image\n",
    "        soup = initializeBrowser(url)\n",
    "        \n",
    "        full_res_image_url = soup.find('div', class_=\"downloads\").find_all('li')[1].find('a')['href']\n",
    "        hemisphere_image_url.append({\"title\": image_title,\"img_url\": full_res_image_url})\n",
    "            \n",
    "    return hemisphere_image_url\n",
    "\n",
    "\n",
    "usgs_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "soup = initializeBrowser(usgs_url)\n",
    "\n",
    "for key in getMarsHemisphereUrls(soup):\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
